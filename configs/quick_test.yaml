model_name: distilbert-base-uncased
max_length: 512
train_batch_size: 16
eval_batch_size: 32
learning_rate: 2.0e-5
weight_decay: 0.01
epochs: 1
warmup_ratio: 0.06
max_grad_norm: 1.0
seed: 42
val_ratio: 0.2
label_column: chef_id
text_fields:
  - recipe_name
  - ingredients
  - tags
  - description
  - steps
padding_strategy: longest
truncation_strategy: longest_first
metric_primary: accuracy
metric_secondary: macro_f1
patience: 2
save_total_limit: 2
output_dir: experiments/distilbert_text_only/artifacts
logging_steps: 50
